{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ef29ce2",
   "metadata": {},
   "source": [
    "## Text Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8647f4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "import pandas as pd\n",
    "df = pd.read_csv('movie.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bae120c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I grew up (b. 1965) watching and loving the Th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When I put this movie in my DVD player, and sa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why do people who do not know what a particula...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Even though I have great interest in Biblical ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Im a die hard Dads Army fan and nothing will e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  I grew up (b. 1965) watching and loving the Th...      0\n",
       "1  When I put this movie in my DVD player, and sa...      0\n",
       "2  Why do people who do not know what a particula...      0\n",
       "3  Even though I have great interest in Biblical ...      0\n",
       "4  Im a die hard Dads Army fan and nothing will e...      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "# Columns: text, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c2fba52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text     0\n",
      "label    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69c780fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 2)\n",
      "(39723, 2)\n"
     ]
    }
   ],
   "source": [
    "# Drop any duplicates\n",
    "print(df.shape)\n",
    "df.drop_duplicates(inplace=True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58d90dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 39723 entries, 0 to 39999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    39723 non-null  object\n",
      " 1   label   39723 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 931.0+ KB\n",
      "None\n",
      "label\n",
      "1    19908\n",
      "0    19815\n",
      "Name: count, dtype: int64\n",
      "              label\n",
      "count  39723.000000\n",
      "mean       0.501171\n",
      "std        0.500005\n",
      "min        0.000000\n",
      "25%        0.000000\n",
      "50%        1.000000\n",
      "75%        1.000000\n",
      "max        1.000000\n"
     ]
    }
   ],
   "source": [
    "# Check for any class imbalances\n",
    "print(df.info())\n",
    "print(df['label'].value_counts())\n",
    "print(df.describe())\n",
    "# Score: the dataset is balanced and good for ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "419b7e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\torre\\AppData\\Local\\Temp\\ipykernel_18136\\2602942683.py:2: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sampled_df = df.groupby('label', group_keys=False).apply(lambda x: x.sample(4000))\n"
     ]
    }
   ],
   "source": [
    "#  Sampling the dataset for computational purposes\n",
    "sampled_df = df.groupby('label', group_keys=False).apply(lambda x: x.sample(4000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "027b189b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import NLTk and download corpus\n",
    "import nltk\n",
    "#nltk.download('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05f6d64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing text \n",
    "# Imports\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "# Will compare lemmatization vs stemming for accuracy\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import re\n",
    "\n",
    "# Initialize stopwords, stemmer, and lemmatizer\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Functions to process with stemming and lemmatization for testing\n",
    "def preprocess_text_stem(text):\n",
    "    text = text.lower() # Lowercase text\n",
    "    text = re.sub(r'[^a-z0-9\\s]', '', text) # Remove punctuation + special characters\n",
    "    tokens = word_tokenize(text) # Tokenize text\n",
    "    # Remove stopwords\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    # Perform stemming\n",
    "    tokens = [stemmer.stem(token) for token in tokens]\n",
    "    \n",
    "    # Join tokens back into a string\n",
    "    text = ' '.join(tokens)\n",
    "    return text\n",
    "\n",
    "def preprocess_text_lemmatize(text):\n",
    "    text = text.lower() # Lowercase text\n",
    "    text = re.sub(r'[^a-z0-9\\s]', '', text) # Remove punctuation + special characters\n",
    "    tokens = word_tokenize(text) # Tokenize text\n",
    "    # Remove stopwords\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "\n",
    "    # Perform lemmatization\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "    # Join tokens back into a string\n",
    "    text = ' '.join(tokens)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb3c3cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemmed samples\n",
      "2401     jack black charact tim dingman dreamer envi fi...\n",
      "5732     watch one episod program couldnt even get end ...\n",
      "26186    went see movi alreadi forc choic origin intent...\n",
      "5895     director jonathan lynn made underr comedi past...\n",
      "39975    could believ aw film rare watch commerci tv th...\n",
      "Name: stemText, dtype: object\n",
      "------------------------------\n",
      "Lemmatized samples\n",
      "2401     jack black character tim dingman dreamer envy ...\n",
      "5732     watched one episode program couldnt even get e...\n",
      "26186    went see movie already forced choice original ...\n",
      "5895     director jonathan lynn made underrated comedy ...\n",
      "39975    could believe awful film rarely watch commerci...\n",
      "Name: lemmatizeText, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Apply the pre-processing functions to the text\n",
    "sampled_df['stemText'] = sampled_df['text'].apply(preprocess_text_stem)\n",
    "sampled_df['lemmatizeText'] = sampled_df['text'].apply(preprocess_text_lemmatize)\n",
    "\n",
    "# Print samples of processed text\n",
    "print(\"Stemmed samples\")\n",
    "print(sampled_df['stemText'].head())\n",
    "print(\"-\"*30)\n",
    "print(\"Lemmatized samples\")\n",
    "print(sampled_df['lemmatizeText'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5b540c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save prepared data\n",
    "sampled_df.to_csv('movies_prepared.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22c97b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset and create word embeddings using TF-IDF\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "X_stem = sampled_df['stemText']\n",
    "X_lemmatize = sampled_df['lemmatizeText']\n",
    "y = sampled_df['label']\n",
    "\n",
    "# Dataset splits for both stemmed and lemmatized words\n",
    "# Random state creates the same splits for both datasets, enusring proper comparison\n",
    "X_train_stem_text, X_test_stem_text, y_train_stem, y_test_stem = train_test_split(\n",
    "    X_stem, y, test_size=0.2, random_state=4444, stratify=y\n",
    ")\n",
    "\n",
    "X_train_lem_text, X_test_lem_text, y_train_lem, y_test_lem = train_test_split(\n",
    "    X_lemmatize, y, test_size=0.2, random_state=4444, stratify=y\n",
    ")\n",
    "\n",
    "# Fit the TF-IDF Vectorizer\n",
    "tfidf_stem = TfidfVectorizer(max_features=20000, ngram_range=(1,2))\n",
    "tfidf_lem = TfidfVectorizer(max_features=20000, ngram_range=(1,2))\n",
    "\n",
    "X_train_stem = tfidf_stem.fit_transform(X_train_stem_text)\n",
    "X_test_stem = tfidf_stem.transform(X_test_stem_text)\n",
    "\n",
    "X_train_lem = tfidf_lem.fit_transform(X_train_lem_text)\n",
    "X_test_lem = tfidf_lem.transform(X_test_lem_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "034f74e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vectorizer_lem.pkl']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Export vectors and labels\n",
    "import joblib\n",
    "\n",
    "# Save features\n",
    "joblib.dump(X_train_stem, \"X_train_stem.pkl\", compress=3)\n",
    "joblib.dump(X_test_stem, \"X_test_stem.pkl\", compress=3)\n",
    "joblib.dump(X_train_lem, \"X_train_lem.pkl\", compress=3)\n",
    "joblib.dump(X_test_lem, \"X_test_lem.pkl\", compress=3)\n",
    "\n",
    "# Save labels \n",
    "joblib.dump(y_train_stem, \"y_train_stem.pkl\")\n",
    "joblib.dump(y_test_stem, \"y_test_stem.pkl\")\n",
    "joblib.dump(y_train_lem, \"y_train_lem.pkl\")\n",
    "joblib.dump(y_test_lem, \"y_test_lem.pkl\")\n",
    "\n",
    "# Save vectorizers\n",
    "joblib.dump(tfidf_stem, \"vectorizer_stem.pkl\")\n",
    "joblib.dump(tfidf_lem, \"vectorizer_lem.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653223f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
